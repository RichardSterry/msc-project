{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Script for developing the speaker recognition model\n",
    "* I built it up as I went along, training in the notebook\n",
    "* Then switched the code to a function and ran it from the notebook\n",
    "\n",
    "29-Jun-18: Last used it today to prepare for Mark Herbster meeting\n",
    "\n",
    "06-Jul-18: Took a copy so I can work on improving the network. I want to get it 'finished' so I can train it and incorporate into the evaluation metrics in the run over the weekend. Then, I'll be able to use it for the next stage of the project.\n",
    "\n",
    "Run in '/home/ubuntu/msc-project-speaker-recognition/msc-project'\n",
    "on aws-big"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Check that everything still runs...\n",
    "* Tweak the issue with the randomizing of samples\n",
    "* Look at Jiameng's code for the next phase\n",
    "* Finalize the architecture...\n",
    "* Check into GitHub etc., move to master branch\n",
    "* Build final trained model within master\n",
    "* Incorporate into the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/msc-project-speaker-recognition/msc-project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('/home/ubuntu/msc-project-speaker-recognition/msc-project')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pydub/utils.py:165: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import visdom\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import NpzFolder, NpzLoader, TBPTTIter\n",
    "from model import Loop, MaskedMSE\n",
    "from utils import create_output_dir, wrap, check_grad\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import notebook_utils as nu\n",
    "\n",
    "import speaker_recognition as sr\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long are the sequences in reality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NpzFolder('/home/ubuntu/loop/data/vctk' + '/numpy_features', False)\n",
    "train_loader = NpzLoader(train_dataset,\n",
    "                         max_seq_len=1000,\n",
    "                         batch_size=1e5,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Valid epoch 1:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "valid_enum = tqdm(train_loader, desc='Valid epoch %d' % epoch)\n",
    "for txt, feat, spkr in valid_enum:\n",
    "    #input = wrap(txt, volatile=True)\n",
    "    #target = wrap(feat, volatile=True)\n",
    "    #spkr = wrap(spkr, volatile=True)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa767c4e910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(feat[1].numpy(), bins=100)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(feat[1].numpy(), 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lens = feat[1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = np.zeros_like(sample_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = [np.random.randint(i+1) for i in np.maximum(0, sample_lens - 300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-61685e2f47f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feat[0][start_idx, :, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8015"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([997, 7839, 63])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on 22 US speaker dataset\n",
    "Smaller and quicker for evaluation purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.073) epoch 0: 100%|██████████| 126/126 [00:45<00:00,  2.75it/s]\n",
      "Evaluation (loss 0.20) epoch 1: 100%|██████████| 126/126 [00:11<00:00, 10.93it/s]\n",
      "Valid epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.05) epoch 1: 100%|██████████| 11/11 [00:01<00:00,  8.78it/s]\n",
      "Train epoch 1:   0%|          | 0/126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.227) epoch 1: 100%|██████████| 126/126 [00:45<00:00,  2.75it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 126/126 [00:11<00:00, 10.94it/s]\n",
      "Valid epoch 1:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.02) epoch 1: 100%|██████████| 11/11 [00:01<00:00,  8.50it/s]\n",
      "Train epoch 2:   0%|          | 0/126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.017) epoch 2:  25%|██▍       | 31/126 [00:11<00:35,  2.69it/s]Process Process-154:\n",
      "Process Process-153:\n",
      "Process Process-155:\n",
      "Process Process-156:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/usr/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 55, in _worker_loop\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "    r = index_queue.get()\n",
      "  File \"data.py\", line 101, in __getitem__\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    racquire()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    txt, feat, spkr = self.loader(path)\n",
      "    r = index_queue.get()\n",
      "    racquire()\n",
      "  File \"/usr/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "KeyboardInterrupt\n",
      "  File \"data.py\", line 125, in loader\n",
      "    return recv()\n",
      "    audio = feat['audio_features']\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.py\", line 233, in __getitem__\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "    pickle_kwargs=self.pickle_kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/numpy/lib/format.py\", line 673, in read_array\n",
      "    data = _read_bytes(fp, read_size, \"array data\")\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/numpy/lib/format.py\", line 812, in _read_bytes\n",
      "    r = fp.read(size - len(data))\n",
      "  File \"/usr/lib/python2.7/zipfile.py\", line 632, in read\n",
      "    data = self.read1(n - len(buf))\n",
      "  File \"/usr/lib/python2.7/zipfile.py\", line 692, in read1\n",
      "    self._update_crc(data, eof=eof)\n",
      "  File \"/usr/lib/python2.7/zipfile.py\", line 644, in _update_crc\n",
      "    self._running_crc = crc32(newdata, self._running_crc) & 0xffffffff\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b56e441243e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                 \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                 \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                                                                 \u001b[0mexp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'20180709_us_22'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                                                                   )\n",
      "\u001b[0;32m/home/ubuntu/msc-project-speaker-recognition/msc-project/speaker_recognition.pyc\u001b[0m in \u001b[0;36mtrain_speaker_recognition\u001b[0;34m(gpu, seed, data_path, nspk, max_seq_len, seq_len, batch_size, num_epochs, exp_name)\u001b[0m\n\u001b[1;32m    518\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                                                     \u001b[0mexp_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 520\u001b[0;31m                                                     gpu=gpu)\n\u001b[0m\u001b[1;32m    521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0mexp_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/msc-project-speaker-recognition/msc-project/speaker_recognition.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data_path, seq_len, nspk, num_epochs, batch_size, max_seq_len, exp_name, gpu)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;31m# Backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \u001b[0;31m#if check_grad(model.parameters(), args.clip_grad, args.ignore_grad):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m#    logging.info('Not a finite gradient or too big, ignoring.')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/__init__.pyc\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net, criterion, train_losses, eval_dict = sr.train_speaker_recognition(data_path = '/home/ubuntu/loop/data/vctk',\n",
    "                                                                nspk = 22,\n",
    "                                                                seq_len = 300,\n",
    "                                                                batch_size = 64,\n",
    "                                                                num_epochs = 10,\n",
    "                                                                exp_name = '20180709_us_22'\n",
    "                                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.991580558745\n",
      "0.982532751092\n"
     ]
    }
   ],
   "source": [
    "print eval_dict['train_accuracy']\n",
    "print eval_dict['valid_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on full VCTK-all dataset\n",
    "This is the one that matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/torch/backends/cudnn/__init__.py:48: UserWarning: PyTorch was compiled without cuDNN support. To use cuDNN, rebuild PyTorch making sure the library is visible to the build system.\n",
      "  \"PyTorch was compiled without cuDNN support. To use cuDNN, rebuild \"\n",
      "Train (loss 0.905) epoch 0: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.91) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.16it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.60) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.40it/s]\n",
      "Train epoch 1:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.059) epoch 1: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.20it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.19) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.38it/s]\n",
      "Train epoch 2:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.059) epoch 2: 100%|██████████| 615/615 [02:55<00:00,  3.51it/s]\n",
      "Evaluation (loss 0.22) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.20it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.11) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.15it/s]\n",
      "Train epoch 3:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.069) epoch 3: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.23it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.02) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.34it/s]\n",
      "Train epoch 4:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.009) epoch 4: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.20it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.08) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.31it/s]\n",
      "Train epoch 5:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.177) epoch 5: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.01) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.20it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.05) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.18it/s]\n",
      "Train epoch 6:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 6: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.17it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.02) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.30it/s]\n",
      "Train epoch 7:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.023) epoch 7: 100%|██████████| 615/615 [02:55<00:00,  3.51it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.19it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.23it/s]\n",
      "Train epoch 8:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.121) epoch 8: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.15it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.01) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.17it/s]\n",
      "Train epoch 9:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.010) epoch 9: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.01) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.21it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.01) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.41it/s]\n",
      "Train epoch 10:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.003) epoch 10: 100%|██████████| 615/615 [02:55<00:00,  3.51it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.15it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.14) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.16it/s]\n",
      "Train epoch 11:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.335) epoch 11: 100%|██████████| 615/615 [02:55<00:00,  3.51it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.18it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.22it/s]\n",
      "Train epoch 12:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.148) epoch 12: 100%|██████████| 615/615 [02:55<00:00,  3.51it/s]\n",
      "Evaluation (loss 0.14) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.16it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.21it/s]\n",
      "Train epoch 13:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 13: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.07) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.18it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.34it/s]\n",
      "Train epoch 14:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.035) epoch 14: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.20it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.24it/s]\n",
      "Train epoch 15:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 15: 100%|██████████| 615/615 [02:55<00:00,  3.51it/s]\n",
      "Evaluation (loss 0.09) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.17it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.02) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.16it/s]\n",
      "Train epoch 16:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 16: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.07) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.15it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.42it/s]\n",
      "Train epoch 17:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 17: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.19it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.01) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.19it/s]\n",
      "Train epoch 18:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 18: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.01) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.19it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.17it/s]\n",
      "Train epoch 19:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.033) epoch 19: 100%|██████████| 615/615 [02:55<00:00,  3.50it/s]\n",
      "Evaluation (loss 0.10) epoch 1: 100%|██████████| 615/615 [00:35<00:00, 17.15it/s]\n",
      "Valid epoch 1:   0%|          | 0/68 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:04<00:00, 16.16it/s]\n",
      "Valid epoch 19:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 19: 100%|██████████| 615/615 [00:35<00:00, 17.17it/s]\n",
      "Evaluation (loss 0.03) epoch 19: 100%|██████████| 68/68 [00:04<00:00, 16.39it/s]\n"
     ]
    }
   ],
   "source": [
    "net, criterion, train_losses, eval_dict = sr.train_speaker_recognition(data_path = '/home/ubuntu/loop/data/vctk-16khz-cmu-no-boundaries-all',\n",
    "                                                                    nspk = 108,\n",
    "                                                                    seq_len = 300,\n",
    "                                                                    batch_size = 64,\n",
    "                                                                    num_epochs = 20,\n",
    "                                                                    exp_name = '20180706')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_loss',\n",
       " 'valid_accuracy',\n",
       " 'valid_gt',\n",
       " 'valid_loss',\n",
       " 'train_accuracy',\n",
       " 'valid_correct',\n",
       " 'valid_pred']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798270893371758"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict['valid_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9919871372466328"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict['train_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_detail = pd.DataFrame(zip(eval_dict['valid_gt'], eval_dict['valid_correct']), columns=('spkr', 'correct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 84/4164\n"
     ]
    }
   ],
   "source": [
    "print \"Num errors: %d/%d\" % (np.sum(eval_dict['valid_correct']==False), len(eval_dict['valid_correct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acc_detail.groupby('spkr').aggregate(('count', 'sum', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spkr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>42</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>41</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>39</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>39</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.897436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>34</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.911765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   sum      mean\n",
       "spkr                       \n",
       "98       42  36.0  0.857143\n",
       "76       41  36.0  0.878049\n",
       "57       39  35.0  0.897436\n",
       "86       39  35.0  0.897436\n",
       "38       34  31.0  0.911765"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].sort_values('mean', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=np.zeros((10,1))\n",
    "valid_loss=np.zeros((10,1))\n",
    "mcd=np.zeros((10,1))\n",
    "train_acc=np.zeros((10,1))\n",
    "valid_acc=np.zeros((10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=( 'train_loss', 'valid_loss', 'mcd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.hstack([vars()[x] for x in columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes 20180706\n",
    "* Implemented randomized segment during training\n",
    "    * Seems to work okay on us-22\n",
    "    * Now running on vctk-all with maxpool, 300\n",
    "        * Got to 98.3% on the valid set after 12 epochs and then fell back a touch in the next two (may have done better if trained for longer)\n",
    "    * vctk-all with 200\n",
    "        * Got to 98.4% after around 11 epochs, may have got a bit more out if trained further?\n",
    "        \n",
    "    * added weight_norm at the end\n",
    "        * bit worse, but hard to be 100% sure\n",
    "        \n",
    "    * double number of conv filters in layers 3 and 4\n",
    "        * Got to 100% on us-22, but was worse on vctk-all (no higher than 96%)\n",
    "        \n",
    "    * added dropout to all the conv layers\n",
    "        * okay for us-22: slower to train, but by 10 epoch validation was 99.7%\n",
    "        * for vctk-all, never gets much above 97%...\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Increase epochs - any improvement? *yes, gets up to 99.9%. Didn't get rid of the last error though*\n",
    "* Vary seq_len. How sensitive? *much faster on seq_len=100. Results similar in the end.*\n",
    "* Run on full dataset... does it work?\n",
    "* Try using random 500 step chunk of non-padded part of each sample -> much more robust?\n",
    "* Then try using mean or rms rather than max, seeing as padding less of an issue?\n",
    "* Then look at whether there's a relationship between the classes than come 2nd/3rd and which speaker embeddings are close based on cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD CODE\n",
    "From the first iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop the speaker recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "seed = 1\n",
    "data = '/home/ubuntu/loop/data/vctk'\n",
    "nspk = 22\n",
    "max_seq_len = 1000\n",
    "seq_len = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(gpu)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap train dataset\n",
    "train_dataset = NpzFolder(data + '/numpy_features', nspk == 1)\n",
    "train_loader = NpzLoader(train_dataset,\n",
    "                         max_seq_len=max_seq_len,\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap validation dataset\n",
    "valid_dataset = NpzFolder(data + '/numpy_features_valid', nspk == 1)\n",
    "valid_loader = NpzLoader(valid_dataset,\n",
    "                         max_seq_len=max_seq_len,\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionNet(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(RecognitionNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # 1 input channel, 32 output channels, 3x3 square convolution\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "                \n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1 * 32 * 53, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, nspk)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print x.size()\n",
    "        #print type(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        #print x.size()\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        #print x.size()\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        #print x.size()\n",
    "        \n",
    "        # ave pooling over time\n",
    "        #x = self.pool(x)\n",
    "        x = torch.max(x, dim=2)[0]\n",
    "        #print x.size()\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #print x.size()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def cuda(self, device_id=None):\n",
    "        nn.Module.cuda(self, device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, epoch=1, eval_losses=[], loader=valid_loader):\n",
    "    total = 0\n",
    "    valid_enum = tqdm(loader, desc='Valid epoch %d' % epoch)\n",
    "    #valid_enum = loader\n",
    "\n",
    "    total_correct = 0.\n",
    "    total_samples = 0.\n",
    "    \n",
    "    num_samples = len(loader.dataset)\n",
    "    all_pred = []\n",
    "    all_gt = []\n",
    "    all_correct = []\n",
    "    \n",
    "    for txt, feat, spkr in valid_enum:\n",
    "        input = wrap(txt, volatile=True)\n",
    "        target = wrap(feat, volatile=True)\n",
    "        spkr = wrap(spkr, volatile=True)\n",
    "\n",
    "        # TODO: run with gradients turned off?\n",
    "        output = net(target[0].transpose(0,1).unsqueeze(1))\n",
    "        loss = criterion(output, spkr.view(-1))\n",
    "        \n",
    "        #output, _ = model([input, spkr], target[0])\n",
    "        #loss = criterion(output, target[0], target[1])\n",
    "\n",
    "        total += loss.data[0]\n",
    "\n",
    "        valid_enum.set_description('Valid (loss %.2f) epoch %d' %\n",
    "                                   (loss.data[0], epoch))\n",
    "        \n",
    "        total_samples += len(spkr)\n",
    "        \n",
    "        spkr_gt = spkr.cpu().view(-1).data.numpy()\n",
    "        spkr_pred = output.cpu().data.numpy().argmax(1)\n",
    "        \n",
    "        correct_pred = spkr_gt == spkr_pred\n",
    "        num_correct_pred = np.sum(correct_pred)\n",
    "        total_correct += num_correct_pred\n",
    "        \n",
    "        all_pred.append(spkr_pred)\n",
    "        all_gt.append(spkr_gt)\n",
    "        all_correct.append(correct_pred)\n",
    "        \n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "            \n",
    "    avg = total / len(valid_loader)\n",
    "    eval_losses.append(avg)\n",
    "   \n",
    "    all_pred = np.concatenate(all_pred)\n",
    "    all_gt = np.concatenate(all_gt)\n",
    "    all_correct = np.concatenate(all_correct)\n",
    "    \n",
    "    return avg, accuracy, all_pred, all_gt, all_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 300\n",
    "epoch = 1\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RecognitionNet(seq_len=seq_len)\n",
    "net.cuda()\n",
    "net.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.09) epoch 0: 100%|██████████| 126/126 [00:35<00:00,  3.57it/s]\n",
      "Train (loss 0.00) epoch 1: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n",
      "Train (loss 0.00) epoch 2: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n",
      "Train (loss 0.00) epoch 3: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n",
      "Train (loss 0.00) epoch 4: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_enum = tqdm(train_loader, desc='Train epoch %d' % epoch)\n",
    "\n",
    "    total = 0\n",
    "    for full_txt, full_feat, spkr in train_enum:\n",
    "        batch_iter = TBPTTIter(full_txt, full_feat, spkr, seq_len)\n",
    "        batch_total = 0\n",
    "\n",
    "        counter = 1\n",
    "        for txt, feat, spkr, start in batch_iter:\n",
    "            input = wrap(txt)\n",
    "            target = wrap(feat)\n",
    "            spkr = wrap(spkr)\n",
    "\n",
    "            # Zero gradients\n",
    "            if start:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            #output = net(target[0].transpose(0,1).unsqueeze(1).cpu())\n",
    "            output = net(target[0].transpose(0,1).unsqueeze(1))\n",
    "            #print output.size()\n",
    "            #print spkr.size()\n",
    "            loss = criterion(output, spkr.view(-1))\n",
    "            #print \"Iteration %d: loss %.2f\" %(counter, loss.data[0])\n",
    "\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            #if check_grad(model.parameters(), args.clip_grad, args.ignore_grad):\n",
    "            #    logging.info('Not a finite gradient or too big, ignoring.')\n",
    "            #    optimizer.zero_grad()\n",
    "            #    continue\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # Keep track of loss\n",
    "            batch_total += loss.data[0]\n",
    "            counter += 1\n",
    "\n",
    "            break\n",
    "\n",
    "        batch_total = batch_total / len(batch_iter)\n",
    "        total += batch_total\n",
    "        train_enum.set_description('Train (loss %.3f) epoch %d' %\n",
    "                                   (batch_total, epoch))\n",
    "        #print \"Train (loss %.2f)\" % (batch_total)\n",
    "\n",
    "        #break\n",
    "    avg = total / len(train_loader)\n",
    "    train_losses.append(avg)\n",
    "\n",
    "\n",
    "#logging.info('====> Train set loss: {:.4f}'.format(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3126998151943244,\n",
       " 0.012177846507506843,\n",
       " 0.005214821041109552,\n",
       " 0.0028364011609218315,\n",
       " 0.005955733493753958]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid (loss 0.00) epoch 1: 100%|██████████| 11/11 [00:01<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.009\n",
      "Accuracy: 0.997\n",
      "Num errors: 2/687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg, accuracy, all_pred, all_gt, all_correct = evaluate(net, criterion, loader=valid_loader)\n",
    "print \"Average Loss: %.3f\" % avg\n",
    "print \"Accuracy: %.3f\" % accuracy\n",
    "print \"Num errors: %d/%d\" % (np.sum(all_correct==False), len(all_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check on the softmax outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "Ground truth speaker: 6\n",
      "Predicted speaker: 6\n",
      "Probability of predicted speaker: 0.559\n",
      "Probability of correct speaker: 0.559\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11b85b1350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "\n",
    "spkr_gt = spkr.cpu().view(-1).data[idx]\n",
    "spkr_pred = sm[idx, :].cpu().data.numpy().argmax()\n",
    "\n",
    "if spkr_gt == spkr_pred:\n",
    "    print \"CORRECT\"\n",
    "else:\n",
    "    print \"*** MISTAKE ***\"\n",
    "        \n",
    "print \"Ground truth speaker: %d\" % spkr_gt\n",
    "print \"Predicted speaker: %d\" % spkr_pred\n",
    "print \"Probability of predicted speaker: %0.3f\" % sm[idx, :].cpu().data.numpy().max()\n",
    "print \"Probability of correct speaker: %0.3f\" % sm[idx, spkr.cpu().view(-1).data[idx]]\n",
    "\n",
    "plt.bar(range(nspk), sm[idx,:].cpu().data.numpy())\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982532751091703"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_detail = pd.DataFrame(zip(all_gt, all_correct), columns=('spkr', 'correct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_detail.groupby('spkr').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#valid_loader.dataset.speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_info = nu.get_vctk_speaker_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(10, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n",
      "torch.Size([10, 32, 26, 26])\n",
      "torch.Size([10, 32, 24, 24])\n",
      "torch.Size([10, 32, 22, 22])\n",
      "torch.Size([10, 22, 22])\n",
      "torch.Size([10, 484])\n"
     ]
    }
   ],
   "source": [
    "output = net(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using speaker_recognition module\n",
    "I then moved all the code into speaker_recognition.py and trained the network from the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.048) epoch 0: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.23) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 1:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.058) epoch 1: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Train epoch 2:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.007) epoch 2: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.04) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.33it/s]\n",
      "Train epoch 3:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.041) epoch 3: 100%|██████████| 615/615 [02:51<00:00,  3.59it/s]\n",
      "Evaluation (loss 0.05) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Train epoch 4:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 4: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 5:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.005) epoch 5: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.04) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 6:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.008) epoch 6: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 7:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.015) epoch 7: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.44) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 8:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.046) epoch 8: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.33it/s]\n",
      "Train epoch 9:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 9: 100%|██████████| 615/615 [03:05<00:00,  3.31it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:11<00:00,  6.00it/s]\n",
      "Train epoch 10:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.018) epoch 10: 100%|██████████| 615/615 [03:25<00:00,  2.99it/s]\n",
      "Evaluation (loss 0.09) epoch 1: 100%|██████████| 68/68 [00:11<00:00,  6.04it/s]\n",
      "Train epoch 11:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.001) epoch 11: 100%|██████████| 615/615 [03:03<00:00,  3.35it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Train epoch 12:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.002) epoch 12: 100%|██████████| 615/615 [02:50<00:00,  3.60it/s]\n",
      "Evaluation (loss 0.18) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 13:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.001) epoch 13: 100%|██████████| 615/615 [02:52<00:00,  3.57it/s]\n",
      "Evaluation (loss 0.25) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.26it/s]\n",
      "Train epoch 14:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 14: 100%|██████████| 615/615 [02:52<00:00,  3.56it/s]\n",
      "Evaluation (loss 0.38) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 15:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 15: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.06) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 16:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 16: 100%|██████████| 615/615 [02:58<00:00,  3.45it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.30it/s]\n",
      "Train epoch 17:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 18: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 19:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.049) epoch 19: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.37it/s]\n",
      "Valid epoch 19:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 19: 100%|██████████| 615/615 [01:21<00:00,  7.58it/s]\n",
      "Evaluation (loss 0.00) epoch 19: 100%|██████████| 68/68 [00:09<00:00,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "net, criterion, train_losses, eval_dict = sr.train_speaker_recognition(data_path = '/home/ubuntu/loop/data/vctk-16khz-cmu-no-boundaries-all',\n",
    "                                                                    nspk = 108,\n",
    "                                                                    seq_len = 300,\n",
    "                                                                    batch_size = 64,\n",
    "                                                                    num_epochs = 20,\n",
    "                                                                    exp_name = 'max_20180629')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_loss',\n",
       " 'valid_accuracy',\n",
       " 'valid_gt',\n",
       " 'valid_loss',\n",
       " 'train_accuracy',\n",
       " 'valid_correct',\n",
       " 'valid_pred']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382804995196926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict['valid_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_detail = pd.DataFrame(zip(eval_dict['valid_gt'], eval_dict['valid_correct']), columns=('spkr', 'correct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 125/4164\n"
     ]
    }
   ],
   "source": [
    "print \"Num errors: %d/%d\" % (np.sum(eval_dict['valid_correct']==False), len(eval_dict['valid_correct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acc_detail.groupby('spkr').aggregate(('count', 'sum', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spkr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>41</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>40</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>42</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   sum      mean\n",
       "spkr                       \n",
       "76       41  33.0  0.804878\n",
       "30       42  35.0  0.833333\n",
       "64       40  34.0  0.850000\n",
       "98       42  36.0  0.857143\n",
       "5        39  34.0  0.871795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].sort_values('mean', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Increase epochs - any improvement? *yes, gets up to 99.9%. Didn't get rid of the last error though*\n",
    "* Vary seq_len. How sensitive? *much faster on seq_len=100. Results similar in the end.*\n",
    "* Run on full dataset... does it work?\n",
    "* Try using random 500 step chunk of non-padded part of each sample -> much more robust?\n",
    "* Then try using mean or rms rather than max, seeing as padding less of an issue?\n",
    "* Then look at whether there's a relationship between the classes than come 2nd/3rd and which speaker embeddings are close based on cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 epochs, seq_len=300\n",
    "* 99.6% accuracy, 3 errors\n",
    "\n",
    "##### 5 epochs, seq_len=100\n",
    "* Much quicker to train!\n",
    "* 99.4% accuracy, 4 errors\n",
    "\n",
    "##### 10 epochs, seq_len=100\n",
    "* 99.9% accuracy... 1 error\n",
    "\n",
    "##### 10 epochs, seq_len=300\n",
    "* 99.9% accuracy... 1 error\n",
    "\n",
    "#### Full dataset\n",
    "\n",
    "##### 10 epochs, seq_len=300\n",
    "* 96.4% accuracy, 148 errors - not too bad as a starting point\n",
    "\n",
    "##### 10 epochs, seq_len=100\n",
    "* 90.0% accuracy - much worse for the full VCTK dataset, which makes sense\n",
    "\n",
    "##### 10 epochs, seq_len=500\n",
    "* 95.9% accuracy - no better\n",
    "\n",
    "##### 20 epochs, seq_len=400\n",
    "* best 97.8% accuracy, finished at 96%... not much better\n",
    "\n",
    "##### 20 epochs, seq_len=300\n",
    "* best 97.7% accuracy, finished at 97%... okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_info = nu.get_vctk_speaker_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
