{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Script for developing the speaker recognition model\n",
    "* I built it up as I went along, training in the notebook\n",
    "* Then switched the code to a function and ran it from the notebook\n",
    "\n",
    "29-Jun-18: Last used it today to prepare for Mark Herbster meeting\n",
    "\n",
    "Run in '/home/ubuntu/msc-project-speaker-recognition/msc-project'\n",
    "on aws-big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/msc-project-speaker-recognition/msc-project'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.chdir('../')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import visdom\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from data import NpzFolder, NpzLoader, TBPTTIter\n",
    "from model import Loop, MaskedMSE\n",
    "from utils import create_output_dir, wrap, check_grad\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import notebook_utils as nu\n",
    "\n",
    "import speaker_recognition as sr\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop the speaker recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "seed = 1\n",
    "data = '/home/ubuntu/loop/data/vctk'\n",
    "nspk = 22\n",
    "max_seq_len = 1000\n",
    "seq_len = 100\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(gpu)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap train dataset\n",
    "train_dataset = NpzFolder(data + '/numpy_features', nspk == 1)\n",
    "train_loader = NpzLoader(train_dataset,\n",
    "                         max_seq_len=max_seq_len,\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap validation dataset\n",
    "valid_dataset = NpzFolder(data + '/numpy_features_valid', nspk == 1)\n",
    "valid_loader = NpzLoader(valid_dataset,\n",
    "                         max_seq_len=max_seq_len,\n",
    "                         batch_size=batch_size,\n",
    "                         num_workers=4,\n",
    "                         pin_memory=True,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognitionNet(nn.Module):\n",
    "    def __init__(self, seq_len):\n",
    "        super(RecognitionNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # 1 input channel, 32 output channels, 3x3 square convolution\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "                \n",
    "        self.conv2 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn4 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(32, 32, 3)\n",
    "        self.bn5 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.pool = nn.MaxPool1d(2, 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1 * 32 * 53, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, nspk)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.pool(F.relu(self.conv1(x)))\n",
    "        #print x.size()\n",
    "        #print type(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        #print x.size()\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        #print x.size()\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        #print x.size()\n",
    "        \n",
    "        # ave pooling over time\n",
    "        #x = self.pool(x)\n",
    "        x = torch.max(x, dim=2)[0]\n",
    "        #print x.size()\n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #print x.size()\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "    def cuda(self, device_id=None):\n",
    "        nn.Module.cuda(self, device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(net, criterion, epoch=1, eval_losses=[], loader=valid_loader):\n",
    "    total = 0\n",
    "    valid_enum = tqdm(loader, desc='Valid epoch %d' % epoch)\n",
    "    #valid_enum = loader\n",
    "\n",
    "    total_correct = 0.\n",
    "    total_samples = 0.\n",
    "    \n",
    "    num_samples = len(loader.dataset)\n",
    "    all_pred = []\n",
    "    all_gt = []\n",
    "    all_correct = []\n",
    "    \n",
    "    for txt, feat, spkr in valid_enum:\n",
    "        input = wrap(txt, volatile=True)\n",
    "        target = wrap(feat, volatile=True)\n",
    "        spkr = wrap(spkr, volatile=True)\n",
    "\n",
    "        # TODO: run with gradients turned off?\n",
    "        output = net(target[0].transpose(0,1).unsqueeze(1))\n",
    "        loss = criterion(output, spkr.view(-1))\n",
    "        \n",
    "        #output, _ = model([input, spkr], target[0])\n",
    "        #loss = criterion(output, target[0], target[1])\n",
    "\n",
    "        total += loss.data[0]\n",
    "\n",
    "        valid_enum.set_description('Valid (loss %.2f) epoch %d' %\n",
    "                                   (loss.data[0], epoch))\n",
    "        \n",
    "        total_samples += len(spkr)\n",
    "        \n",
    "        spkr_gt = spkr.cpu().view(-1).data.numpy()\n",
    "        spkr_pred = output.cpu().data.numpy().argmax(1)\n",
    "        \n",
    "        correct_pred = spkr_gt == spkr_pred\n",
    "        num_correct_pred = np.sum(correct_pred)\n",
    "        total_correct += num_correct_pred\n",
    "        \n",
    "        all_pred.append(spkr_pred)\n",
    "        all_gt.append(spkr_gt)\n",
    "        all_correct.append(correct_pred)\n",
    "        \n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "            \n",
    "    avg = total / len(valid_loader)\n",
    "    eval_losses.append(avg)\n",
    "   \n",
    "    all_pred = np.concatenate(all_pred)\n",
    "    all_gt = np.concatenate(all_gt)\n",
    "    all_correct = np.concatenate(all_correct)\n",
    "    \n",
    "    return avg, accuracy, all_pred, all_gt, all_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 300\n",
    "epoch = 1\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = RecognitionNet(seq_len=seq_len)\n",
    "net.cuda()\n",
    "net.train()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.09) epoch 0: 100%|██████████| 126/126 [00:35<00:00,  3.57it/s]\n",
      "Train (loss 0.00) epoch 1: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n",
      "Train (loss 0.00) epoch 2: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n",
      "Train (loss 0.00) epoch 3: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n",
      "Train (loss 0.00) epoch 4: 100%|██████████| 126/126 [00:35<00:00,  3.56it/s]\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_enum = tqdm(train_loader, desc='Train epoch %d' % epoch)\n",
    "\n",
    "    total = 0\n",
    "    for full_txt, full_feat, spkr in train_enum:\n",
    "        batch_iter = TBPTTIter(full_txt, full_feat, spkr, seq_len)\n",
    "        batch_total = 0\n",
    "\n",
    "        counter = 1\n",
    "        for txt, feat, spkr, start in batch_iter:\n",
    "            input = wrap(txt)\n",
    "            target = wrap(feat)\n",
    "            spkr = wrap(spkr)\n",
    "\n",
    "            # Zero gradients\n",
    "            if start:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            #output = net(target[0].transpose(0,1).unsqueeze(1).cpu())\n",
    "            output = net(target[0].transpose(0,1).unsqueeze(1))\n",
    "            #print output.size()\n",
    "            #print spkr.size()\n",
    "            loss = criterion(output, spkr.view(-1))\n",
    "            #print \"Iteration %d: loss %.2f\" %(counter, loss.data[0])\n",
    "\n",
    "            # Backward\n",
    "            loss.backward()\n",
    "            #if check_grad(model.parameters(), args.clip_grad, args.ignore_grad):\n",
    "            #    logging.info('Not a finite gradient or too big, ignoring.')\n",
    "            #    optimizer.zero_grad()\n",
    "            #    continue\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            # Keep track of loss\n",
    "            batch_total += loss.data[0]\n",
    "            counter += 1\n",
    "\n",
    "            break\n",
    "\n",
    "        batch_total = batch_total / len(batch_iter)\n",
    "        total += batch_total\n",
    "        train_enum.set_description('Train (loss %.3f) epoch %d' %\n",
    "                                   (batch_total, epoch))\n",
    "        #print \"Train (loss %.2f)\" % (batch_total)\n",
    "\n",
    "        #break\n",
    "    avg = total / len(train_loader)\n",
    "    train_losses.append(avg)\n",
    "\n",
    "\n",
    "#logging.info('====> Train set loss: {:.4f}'.format(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3126998151943244,\n",
       " 0.012177846507506843,\n",
       " 0.005214821041109552,\n",
       " 0.0028364011609218315,\n",
       " 0.005955733493753958]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Valid (loss 0.00) epoch 1: 100%|██████████| 11/11 [00:01<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.009\n",
      "Accuracy: 0.997\n",
      "Num errors: 2/687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg, accuracy, all_pred, all_gt, all_correct = evaluate(net, criterion, loader=valid_loader)\n",
    "print \"Average Loss: %.3f\" % avg\n",
    "print \"Accuracy: %.3f\" % accuracy\n",
    "print \"Num errors: %d/%d\" % (np.sum(all_correct==False), len(all_correct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check on the softmax outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = F.softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORRECT\n",
      "Ground truth speaker: 6\n",
      "Predicted speaker: 6\n",
      "Probability of predicted speaker: 0.559\n",
      "Probability of correct speaker: 0.559\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11b85b1350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 2\n",
    "\n",
    "spkr_gt = spkr.cpu().view(-1).data[idx]\n",
    "spkr_pred = sm[idx, :].cpu().data.numpy().argmax()\n",
    "\n",
    "if spkr_gt == spkr_pred:\n",
    "    print \"CORRECT\"\n",
    "else:\n",
    "    print \"*** MISTAKE ***\"\n",
    "        \n",
    "print \"Ground truth speaker: %d\" % spkr_gt\n",
    "print \"Predicted speaker: %d\" % spkr_pred\n",
    "print \"Probability of predicted speaker: %0.3f\" % sm[idx, :].cpu().data.numpy().max()\n",
    "print \"Probability of correct speaker: %0.3f\" % sm[idx, spkr.cpu().view(-1).data[idx]]\n",
    "\n",
    "plt.bar(range(nspk), sm[idx,:].cpu().data.numpy())\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982532751091703"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_detail = pd.DataFrame(zip(all_gt, all_correct), columns=('spkr', 'correct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acc_detail.groupby('spkr').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#valid_loader.dataset.speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_info = nu.get_vctk_speaker_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(10, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28])\n",
      "torch.Size([10, 32, 26, 26])\n",
      "torch.Size([10, 32, 24, 24])\n",
      "torch.Size([10, 32, 22, 22])\n",
      "torch.Size([10, 22, 22])\n",
      "torch.Size([10, 484])\n"
     ]
    }
   ],
   "source": [
    "output = net(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using speaker_recognition module\n",
    "I then moved all the code into speaker_recognition.py and trained the network from the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.048) epoch 0: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.23) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 1:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.058) epoch 1: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Train epoch 2:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.007) epoch 2: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.04) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.33it/s]\n",
      "Train epoch 3:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.041) epoch 3: 100%|██████████| 615/615 [02:51<00:00,  3.59it/s]\n",
      "Evaluation (loss 0.05) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Train epoch 4:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 4: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 5:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.005) epoch 5: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.04) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 6:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.008) epoch 6: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 7:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.015) epoch 7: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.44) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 8:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.046) epoch 8: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.33it/s]\n",
      "Train epoch 9:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 9: 100%|██████████| 615/615 [03:05<00:00,  3.31it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:11<00:00,  6.00it/s]\n",
      "Train epoch 10:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.018) epoch 10: 100%|██████████| 615/615 [03:25<00:00,  2.99it/s]\n",
      "Evaluation (loss 0.09) epoch 1: 100%|██████████| 68/68 [00:11<00:00,  6.04it/s]\n",
      "Train epoch 11:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.001) epoch 11: 100%|██████████| 615/615 [03:03<00:00,  3.35it/s]\n",
      "Evaluation (loss 0.16) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.34it/s]\n",
      "Train epoch 12:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.002) epoch 12: 100%|██████████| 615/615 [02:50<00:00,  3.60it/s]\n",
      "Evaluation (loss 0.18) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 13:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.001) epoch 13: 100%|██████████| 615/615 [02:52<00:00,  3.57it/s]\n",
      "Evaluation (loss 0.25) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.26it/s]\n",
      "Train epoch 14:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 14: 100%|██████████| 615/615 [02:52<00:00,  3.56it/s]\n",
      "Evaluation (loss 0.38) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.35it/s]\n",
      "Train epoch 15:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 15: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.06) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 16:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 16: 100%|██████████| 615/615 [02:58<00:00,  3.45it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.30it/s]\n",
      "Train epoch 17:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.000) epoch 18: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.03) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.36it/s]\n",
      "Train epoch 19:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train (loss 0.049) epoch 19: 100%|██████████| 615/615 [02:49<00:00,  3.63it/s]\n",
      "Evaluation (loss 0.00) epoch 1: 100%|██████████| 68/68 [00:09<00:00,  7.37it/s]\n",
      "Valid epoch 19:   0%|          | 0/615 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation (loss 0.00) epoch 19: 100%|██████████| 615/615 [01:21<00:00,  7.58it/s]\n",
      "Evaluation (loss 0.00) epoch 19: 100%|██████████| 68/68 [00:09<00:00,  7.33it/s]\n"
     ]
    }
   ],
   "source": [
    "net, criterion, train_losses, eval_dict = sr.train_speaker_recognition(data_path = '/home/ubuntu/loop/data/vctk-16khz-cmu-no-boundaries-all',\n",
    "                                                                    nspk = 108,\n",
    "                                                                    seq_len = 300,\n",
    "                                                                    batch_size = 64,\n",
    "                                                                    num_epochs = 20,\n",
    "                                                                    exp_name = 'max_20180629')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_loss',\n",
       " 'valid_accuracy',\n",
       " 'valid_gt',\n",
       " 'valid_loss',\n",
       " 'train_accuracy',\n",
       " 'valid_correct',\n",
       " 'valid_pred']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382804995196926"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dict['valid_accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_detail = pd.DataFrame(zip(eval_dict['valid_gt'], eval_dict['valid_correct']), columns=('spkr', 'correct'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num errors: 125/4164\n"
     ]
    }
   ],
   "source": [
    "print \"Num errors: %d/%d\" % (np.sum(eval_dict['valid_correct']==False), len(eval_dict['valid_correct']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acc_detail.groupby('spkr').aggregate(('count', 'sum', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spkr</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>41</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>42</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>40</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>42</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.871795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      count   sum      mean\n",
       "spkr                       \n",
       "76       41  33.0  0.804878\n",
       "30       42  35.0  0.833333\n",
       "64       40  34.0  0.850000\n",
       "98       42  36.0  0.857143\n",
       "5        39  34.0  0.871795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['correct'].sort_values('mean', ascending=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* Increase epochs - any improvement? *yes, gets up to 99.9%. Didn't get rid of the last error though*\n",
    "* Vary seq_len. How sensitive? *much faster on seq_len=100. Results similar in the end.*\n",
    "* Run on full dataset... does it work?\n",
    "* Try using random 500 step chunk of non-padded part of each sample -> much more robust?\n",
    "* Then try using mean or rms rather than max, seeing as padding less of an issue?\n",
    "* Then look at whether there's a relationship between the classes than come 2nd/3rd and which speaker embeddings are close based on cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 epochs, seq_len=300\n",
    "* 99.6% accuracy, 3 errors\n",
    "\n",
    "##### 5 epochs, seq_len=100\n",
    "* Much quicker to train!\n",
    "* 99.4% accuracy, 4 errors\n",
    "\n",
    "##### 10 epochs, seq_len=100\n",
    "* 99.9% accuracy... 1 error\n",
    "\n",
    "##### 10 epochs, seq_len=300\n",
    "* 99.9% accuracy... 1 error\n",
    "\n",
    "#### Full dataset\n",
    "\n",
    "##### 10 epochs, seq_len=300\n",
    "* 96.4% accuracy, 148 errors - not too bad as a starting point\n",
    "\n",
    "##### 10 epochs, seq_len=100\n",
    "* 90.0% accuracy - much worse for the full VCTK dataset, which makes sense\n",
    "\n",
    "##### 10 epochs, seq_len=500\n",
    "* 95.9% accuracy - no better\n",
    "\n",
    "##### 20 epochs, seq_len=400\n",
    "* best 97.8% accuracy, finished at 96%... not much better\n",
    "\n",
    "##### 20 epochs, seq_len=300\n",
    "* best 97.7% accuracy, finished at 97%... okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_info = nu.get_vctk_speaker_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#speaker_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
